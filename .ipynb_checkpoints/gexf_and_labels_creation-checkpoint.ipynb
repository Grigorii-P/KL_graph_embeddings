{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gexf graphs creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for python 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import networkx as nx\n",
    "from time import time\n",
    "import json\n",
    "import random\n",
    "from random import shuffle\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_generator(len_):\n",
    "    return \"\".join(random.choice(string.ascii_letters) for j in range(len_))\n",
    "\n",
    "def count_non_unique_names(dic, non_uniques={}):\n",
    "    for key in dic:\n",
    "        if key in non_uniques:\n",
    "                non_uniques[key] += 1\n",
    "        else:\n",
    "            non_uniques[key] = 0\n",
    "        if type(dic[key]) is dict:\n",
    "            count_non_unique_names(dic[key], non_uniques)\n",
    "    res = {}\n",
    "    for key in non_uniques:\n",
    "        if non_uniques[key] > 0:\n",
    "            res[key] = non_uniques[key]\n",
    "    return res\n",
    "\n",
    "def how_many_non_uniques(d, counts={}):\n",
    "    for key in d:\n",
    "        if key not in counts:\n",
    "            counts[key] = 0\n",
    "        else:\n",
    "            counts[key] += 1\n",
    "        \n",
    "        if type(d[key]) is dict:\n",
    "            _ = how_many_non_uniques(d[key], counts)\n",
    "            \n",
    "    return sum(counts.values())\n",
    "            \n",
    "def change_non_unique_names(dic, non_uniques, new_dic={}):\n",
    "    for key in dic:\n",
    "        if key in non_uniques:\n",
    "                split = key.split('.')\n",
    "                if len(split) > 1:\n",
    "                    before_dot = ''.join(split[:len(split)-1])\n",
    "                    new_key = before_dot + word_generator(5) + '.' + split[-1]\n",
    "                else:\n",
    "                    whole_name = split[0]\n",
    "                    new_key = whole_name + word_generator(5)\n",
    "                non_uniques[key] -= 1\n",
    "                if non_uniques[key] == -1:\n",
    "                    del non_uniques[key]\n",
    "        else:\n",
    "            new_key = key\n",
    "        \n",
    "        if type(dic[key]) is dict:\n",
    "            temp = change_non_unique_names(dic[key], non_uniques, {})\n",
    "            new_dic[new_key] = temp\n",
    "        else:\n",
    "            new_dic[new_key] = dic[key]\n",
    "    return new_dic  \n",
    "                        \n",
    "def create_nodes_and_edges(G, dic, root):\n",
    "    for key in dic:\n",
    "        if type(dic[key]) is dict:\n",
    "            G.add_node(key, label=key)\n",
    "            G.add_edge(root, key)\n",
    "            G = create_nodes_and_edges(G, dic[key], key)\n",
    "        else:\n",
    "            G.add_node(key, label=dic[key])\n",
    "            G.add_edge(root, key)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path_chunks = '/home/pogorelov/data/'\n",
    "# path_to_save = '/home/pogorelov/gexf_graphs/'\n",
    "path_chunks = '/Users/grigoriipogorelov/Desktop/chunks/'\n",
    "path_to_save = '/Users/grigoriipogorelov/Desktop/graphs/'\n",
    "path_to_output = '/Users/grigoriipogorelov/Desktop/output.txt'\n",
    "\n",
    "files = []\n",
    "portion = 0.1\n",
    "for filename in os.listdir(path_chunks):\n",
    "    files.append(filename)\n",
    "# shuffle(files)\n",
    "# num_chunks_to_read = int(float(len(files))*portion)\n",
    "# files = files[:num_chunks_to_read]\n",
    "\n",
    "num_chunks_to_print = int(float(len(files))*portion)\n",
    "failed_jbls = {}\n",
    "count_jbl = 0\n",
    "f=open(path_to_output,\"w\")\n",
    "start = time()\n",
    "\n",
    "for file_ in files:\n",
    "    try:\n",
    "        chunk = joblib.load(path_chunks + file_)\n",
    "    except:\n",
    "        continue\n",
    "    for i, item in enumerate(chunk):\n",
    "        non_unique_nodes = count_non_unique_names(item[1], {})\n",
    "        if any(non_unique_nodes):\n",
    "            graph_dict = change_non_unique_names(item[1], non_unique_nodes, {})\n",
    "        else:\n",
    "            graph_dict = item[1]\n",
    "        G = nx.Graph()\n",
    "        G.add_node('APK_ROOT', label='APK_ROOT')\n",
    "        G = create_nodes_and_edges(G, graph_dict, 'APK_ROOT')\n",
    "        nx.write_gexf(G, path_to_save + item[0] + '.gexf')\n",
    "    count_jbl += 1\n",
    "    try:\n",
    "        if count_jbl % num_chunks_to_print == 0:\n",
    "            print >> f, '[%d] chunks are read' % count_jbl\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "\n",
    "end = time()\n",
    "    \n",
    "print >> f, 'created %d gexfs in %0.2f min' % (len(files), (end - start)/60)\n",
    "print >> f, ' '\n",
    "\n",
    "_,_,chunks_num = os.walk(path_chunks).next()\n",
    "print >> f, '%d chunks in %s ' % (len(chunks_num),path_chunks)\n",
    "_,_,gexf_num = os.walk(path_to_save).next()\n",
    "print >> f, '%d gexf graphs in %s ' % (len(gexf_num),path_to_save)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/grigoriipogorelov/Desktop/test/degrees/initial_relab.txt', 'w') as file:\n",
    "    pickle.dump(to_file_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {u'AndroidManifest.xml': 'AXML_PLUS',\n",
    "#  u'abc': {u'assets': u'CERT_NORM',\n",
    "#   u'CERT.SF': u'SIG_PLUS', u'asd':{'asd':'qwe'},\n",
    "#   u'MANIFEST.MF': u'MANIF_PLUS'},\n",
    "#  u'assets': {u'AndroidManifest.xml': u'PNG_NORM',\n",
    "#   u'assets': u'PNG_NORM'},\n",
    "#     u'MANIFEST.MF': u'MANIF_PLUS'}\n",
    "\n",
    "# r = count_non_unique_names(d, {})\n",
    "# new_d = change_non_unique_names(d, r, {})\n",
    "# how_many_non_uniques(d, {}), how_many_non_uniques(new_d, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "\n",
    "# # We can set the number of bins with the `bins` kwarg\n",
    "# n_bins = 60\n",
    "# axs[0].hist(before, bins=n_bins)\n",
    "# axs[1].hist(after, bins=n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import json\n",
    "import ast\n",
    "import utils as u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create only malware and benign (without pua)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.create_equal_portions(dst_file='labels_30000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean 0.5, malw 0.5\n"
     ]
    }
   ],
   "source": [
    "a = json.load(open('labels_30000.txt'))\n",
    "u.test_proportions_from_dict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_path = '/Users/grigoriipogorelov/Desktop/KL/v7/'\n",
    "# datasets = [common_path + 'clean_g.csv', common_path + 'malw_g.csv', common_path + 'pua_g.csv']\n",
    "# path_to_all_labels_file = '/Users/grigoriipogorelov/Desktop/KL_graph_embeddings/KL_graph_embeddings/all_labels.txt'\n",
    "# u.create_all_labels_dict_file_from_csv(datasets, path_to_all_labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path_to_gexf = '/Users/grigoriipogorelov/Desktop/KL/gexf_graphs/'\n",
    "# path_to_labels_file = '/Users/grigoriipogorelov/Desktop/KL/labels.Labels'\n",
    "\n",
    "# _,_,files = os.walk(path_to_gexf).next()\n",
    "\n",
    "# with open(path_to_labels_file, 'w') as f:\n",
    "#     for file_ in files:\n",
    "#         clean, malw, pua = False, False, False\n",
    "#         count +=1\n",
    "#         spl = file_.split('.')\n",
    "#         name = spl[0]\n",
    "#         if name in clean_g_list:\n",
    "#             clean = True\n",
    "#         if name in malw_g_list:\n",
    "#             malw = True\n",
    "#         if name in pua_g_list:\n",
    "#             pua = True\n",
    "            \n",
    "#         if clean and pua:\n",
    "#             f.write(file_+' '+'2'+'\\n')\n",
    "#             continue\n",
    "#         if malw and pua:\n",
    "#             f.write(file_+' '+'1'+'\\n')\n",
    "#             continue\n",
    "#         if clean:\n",
    "#             f.write(file_+' '+'0'+'\\n')\n",
    "#         if malw:\n",
    "#             f.write(file_+' '+'1'+'\\n')\n",
    "#         if pua:\n",
    "#             f.write(file_+' '+'2'+'\\n')\n",
    "\n",
    "# len(missed), len(files), count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('/Users/grigoriipogorelov/Desktop/KL/clean_g.txt') as f:\n",
    "#     clean_g_list = f.readlines()\n",
    "# clean_g_list = [x.strip() for x in clean_g_list]\n",
    "\n",
    "# with open('/Users/grigoriipogorelov/Desktop/KL/malw_g.txt') as f:\n",
    "#     malw_g_list = f.readlines()\n",
    "# malw_g_list = [x.strip() for x in malw_g_list]\n",
    "\n",
    "# with open('/Users/grigoriipogorelov/Desktop/KL/pua_g.txt') as f:\n",
    "#     pua_g_list = f.readlines()\n",
    "# pua_g_list = [x.strip() for x in pua_g_list]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_creation",
   "language": "python",
   "name": "graph_creation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
